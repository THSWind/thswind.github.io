{"title":"Tensorflow-keras notes","date":"2019-11-05T04:59:59.000Z","date_formatted":{"ll":"Nov 5, 2019","L":"11/05/2019","MM-DD":"11-05"},"link":"2019/11/05/Tensorflow-keras notes","comments":true,"tags":["Tensorflow"],"updated":"2019-11-05T04:59:59.000Z","content":"<p>我们应该学会站在前辈们的肩膀上，目前已经有人利用 keras实现了常用的深度学习模型 LeNet， AlexNet， ZFNet， VGGNet， GoogleNet，Resnet。推荐一篇博文如下：</p>\n<p><a href=\"https://blog.csdn.net/wang1127248268/article/details/77258055\" target=\"_blank\">https://blog.csdn.net/wang1127248268/article/details/77258055</a></p>\n<h1 id=\"1-keras介绍与安装\">1 keras介绍与安装<a title=\"#1-keras介绍与安装\" href=\"#1-keras介绍与安装\"></a></h1>\n<ul>\n<li>\n<p>官网</p>\n<p><a href=\"https://keras.io\" target=\"_blank\">https://keras.io</a></p>\n</li>\n<li>\n<p>安装</p>\n<p><code>pip install keras</code></p>\n<p>如果提示需要升级，则输入</p>\n<p><code>python -m pip install --upgrade pip</code></p>\n<p>可通过 python-&gt; import keras 检测是否安装成功。</p>\n</li>\n</ul>\n<h1 id=\"2-keras实现线性回归\">2 keras实现线性回归<a title=\"#2-keras实现线性回归\" href=\"#2-keras实现线性回归\"></a></h1>\n<p>`# -<em>- coding: utf-8 -</em>-`</p>\n<p><code>&quot;&quot;&quot;</code></p>\n<p><code>Created on Tue Nov  5 14:27:20 2019</code></p>\n<p><code>@author: THSWind</code></p>\n<p><code>&quot;&quot;&quot;</code></p>\n<p><code>import keras</code></p>\n<p><code>import numpy as np</code></p>\n<p><code>import matplotlib.pyplot as plt</code></p>\n<p><code>\\#按顺序构成的模型</code></p>\n<p><code>from keras.models import Sequential</code></p>\n<p><code>\\#Dense全连接层</code></p>\n<p><code>from keras.layers import Dense</code></p>\n<p><code>\\#使用numpy生成100个随机点</code></p>\n<p><code>x_data=np.random.rand(100)</code></p>\n<p><code>noise=np.random.normal(0,0.01,x_data.shape)</code></p>\n<p><code>y_data=x_data*0.1+0.2+noise</code></p>\n<p><code>\\#显示随机点</code></p>\n<p><code>plt.scatter(x_data,y_data)</code></p>\n<p><code>plt.show()</code></p>\n<p><code>\\#构建一个顺序模型</code></p>\n<p><code>model=Sequential()</code></p>\n<p><code>\\#在模型中添加一个全连接层</code></p>\n<p><code>model.add(Dense(units=1,input_dim=1))</code></p>\n<p><code>model.compile(optimizer='sgd',loss='mse')</code></p>\n<p><code>\\#训练模型</code></p>\n<p><code>for step in range(3001):</code></p>\n<p>​    <code>\\#每次训练一个批次</code></p>\n<p>​    <code>cost = model.train_on_batch(x_data,y_data)</code></p>\n<p>​    <code>\\#每500个batch打印一次cost值</code></p>\n<p>​    <code>if step % 500 == 0:</code></p>\n<p>​        <code>print('cost',cost)</code></p>\n<p><code>\\#打印权值和偏置值</code></p>\n<p><code>W,b=model.layers[0].get_weights()</code></p>\n<p><code>print('W:',W, 'b',b)</code></p>\n<p><code>\\#x_data输入网络中，得到预测值y_pred</code></p>\n<p><code>y_pred = model.predict(x_data)</code></p>\n<p><code>\\#显示随机点</code></p>\n<p><code>plt.scatter(x_data,y_data)</code></p>\n<p><code>\\#显示预测结果</code></p>\n<p><code>plt.plot(x_data,y_pred,'r-',lw=3)  #lw表示线条宽度</code></p>\n<p><code>plt.show()</code></p>\n<h1 id=\"3-keras非线性回归\">3 keras非线性回归<a title=\"#3-keras非线性回归\" href=\"#3-keras非线性回归\"></a></h1>\n<p>`# -<em>- coding:utf-8 -</em>-`</p>\n<p><code>'''</code></p>\n<p><code>\\* @Author: THSWind</code></p>\n<p><code>\\* @Date: 2019-11-05 15:39:27</code></p>\n<p><code>'''</code></p>\n<p><code>import keras</code></p>\n<p><code>import numpy as np</code></p>\n<p><code>import matplotlib.pyplot as plt</code></p>\n<p><code>\\#按顺序构成的模型</code></p>\n<p><code>from keras.models import Sequential</code></p>\n<p><code>\\#Dense全连接层</code></p>\n<p><code>from keras.layers import Dense,Activation</code></p>\n<p><code>from keras.optimizers import SGD</code></p>\n<p><code>\\#</code></p>\n<p><code>x_data = np.linspace(-0.5,0.5,200)</code></p>\n<p><code>noise = np.random.normal(0,0.02,x_data.shape)</code></p>\n<p><code>y_data = np.square(x_data) + noise</code></p>\n<p><code>\\# 显示随机点</code></p>\n<p><code>plt.scatter(x_data,y_data)</code></p>\n<p><code>plt.show()</code></p>\n<p><code>\\#构建一个顺序模型</code></p>\n<p><code>model=Sequential()</code></p>\n<p><code>\\#在模型中添加一个全连接层</code></p>\n<p><code>\\# 1-10-1</code></p>\n<p><code>\\#定义优化算法</code></p>\n<p><code>sgd = SGD(lr=0.3)    # 由于默认的sgd学习率较小，所以导入SGD，自定义学习率加快学习时间</code></p>\n<p><code>\\# 不添加激活函数，则拟合的曲线仍然可能是直线。因为默认的激活函数是一条直线f(x)=x</code></p>\n<p><code>model.add(Dense(units=10,input_dim=1))</code></p>\n<p><code>model.add(Activation('tanh'))</code></p>\n<p><code>model.add(Dense(units=1))</code></p>\n<p><code>model.add(Activation('tanh'))</code></p>\n<p><code>model.compile(optimizer=sgd,loss='mse')</code></p>\n<p><code>\\# tanh 在大多数情况下比 sigmoid好用 ————吴恩达</code></p>\n<p><code>\\#训练模型</code></p>\n<p><code>for step in range(3001):</code></p>\n<p>​    <code>\\#每次训练一个批次</code></p>\n<p>​    <code>cost = model.train_on_batch(x_data,y_data)</code></p>\n<p>​    <code>\\#每500个batch打印一次cost值</code></p>\n<p>​    <code>if step % 500 == 0:</code></p>\n<p>​        <code>print('cost',cost)</code></p>\n<p><code>\\#打印权值和偏置值</code></p>\n<p><code>W,b=model.layers[0].get_weights()</code></p>\n<p><code>print('W:',W, 'b',b)</code></p>\n<p><code>\\#x_data输入网络中，得到预测值y_pred</code></p>\n<p><code>y_pred = model.predict(x_data)</code></p>\n<p><code>\\#显示随机点</code></p>\n<p><code>plt.scatter(x_data,y_data)</code></p>\n<p><code>\\#显示预测结果</code></p>\n<p><code>plt.plot(x_data,y_pred,'r-',lw=3)  #lw表示线条宽度</code></p>\n<p><code>plt.show()</code></p>\n<h1 id=\"4-mnist分类程序\">4 MNIST分类程序<a title=\"#4-mnist分类程序\" href=\"#4-mnist分类程序\"></a></h1>\n<p>`# -<em>- coding:utf-8 -</em>-`</p>\n<p><code>'''</code></p>\n<p><code>\\* @Author: THSWind</code></p>\n<p><code>\\* @Date: 2019-11-05 16:09:06</code></p>\n<p><code>'''</code></p>\n<p><code>import numpy as np</code></p>\n<p><code>from keras.datasets import mnist</code></p>\n<p><code>from keras.utils import np_utils</code></p>\n<p><code>from keras.models import Sequential</code></p>\n<p><code>from keras.layers import Dense</code></p>\n<p><code>from keras.optimizers import SGD</code></p>\n<p><code>\\# 载入数据</code></p>\n<p><code>(x_train,y_train),(x_test,y_test)= mnist.load_data()</code></p>\n<p><code>\\# (60000,28,28)</code></p>\n<p><code>print('x_shape: ',x_train.shape)</code></p>\n<p><code>\\#(60000)</code></p>\n<p><code>print('y_shape: ', y_train.shape)</code></p>\n<p><code>\\#(60000,28,28)-&gt;(60000,784)</code></p>\n<p><code>x_train=x_train.reshape(x_train.shape[0], -1)/255.0</code></p>\n<p><code>x_test=x_test.reshape(x_test.shape[0], -1)/255.0</code></p>\n<p><code>\\# 转化label为 one-hot格式</code></p>\n<p><code>y_train=np_utils.to_categorical(y_train, num_classes=10)</code></p>\n<p><code>y_test=np_utils.to_categorical(y_test, num_classes=10)</code></p>\n<p><code>\\# 创建模型 输入784个神经元，输出10个神经元</code></p>\n<p><code>model = Sequential([</code></p>\n<p>​    <code>Dense(units=10, input_dim=784, bias_initializer='one',activation='softmax')</code></p>\n<p><code>])</code></p>\n<p><code>\\# 定义优化器</code></p>\n<p><code>sgd = SGD(lr=0.2)</code></p>\n<p><code>\\# 定义优化器， loss function,训练过程中计算准确率</code></p>\n<p><code>model.compile(</code></p>\n<p>​    <code>optimizer=sgd,</code></p>\n<p>​    <code>loss='mse',</code></p>\n<p>​    <code>metrics=['accuracy'],</code></p>\n<p><code>)</code></p>\n<p><code>\\# 训练模型</code></p>\n<p><code>model.fit(x_train,y_train,batch_size=32,epochs=10)</code></p>\n<p><code>\\# 评估模型</code></p>\n<p><code>loss,accuracy=model.evaluate(x_test,y_test)</code></p>\n<p><code>print('\\ntest loss',loss)</code></p>\n<p><code>print('accuracy', accuracy)</code></p>\n<h1 id=\"5-交叉熵应用\">5 交叉熵应用<a title=\"#5-交叉熵应用\" href=\"#5-交叉熵应用\"></a></h1>\n<p><code>model.compile(</code></p>\n<p>​    <code>optimizer=sgd,</code></p>\n<p>​    <code>loss='categorical_crossentropy',  # 改为交叉熵</code></p>\n<p>​    <code>metrics=['accuracy'],</code></p>\n<p><code>)</code></p>\n<h1 id=\"6-dropout\">6 Dropout<a title=\"#6-dropout\" href=\"#6-dropout\"></a></h1>\n<p><code>from keras.layers import Dense,Dropout</code></p>\n<p><code>.......</code></p>\n<p>#drop(0.4) 表示让40%的神经元不工作</p>\n<p><code>model = Sequential([</code></p>\n<p>​    <code>Dense(units=200, input_dim=784, bias_initializer='one',activation='tanh'),</code></p>\n<p>​    <code>Dropout(0.4),</code></p>\n<p>​    <code>Dense(units=200,  bias_initializer='one',activation='tanh'),</code></p>\n<p>​    <code>Dropout(0.4),</code></p>\n<p>​    <code>Dense(units=10,  bias_initializer='one',activation='softmax'),</code></p>\n<p><code>])</code></p>\n<h1 id=\"7-正则化\">7 正则化<a title=\"#7-正则化\" href=\"#7-正则化\"></a></h1>\n<p><code>from keras.regularizers import l2</code></p>\n<p><code>.......</code></p>\n<p><code>model = Sequential([</code></p>\n<p>​    <code>Dense(units=200, input_dim=784, bias_initializer='one',activation='tanh',kernel_regularizer=l2(0.0003)),</code></p>\n<p>​    <code>Dense(units=200,  bias_initializer='one',activation='tanh',kernel_regularizer=l2(0.0003)),</code></p>\n<p>​    <code>Dense(units=10,  bias_initializer='one',activation='softmax',kernel_regularizer=l2(0.0003)),</code></p>\n<p><code>])</code></p>\n<h1 id=\"8-cnn手写识别\">8 CNN手写识别<a title=\"#8-cnn手写识别\" href=\"#8-cnn手写识别\"></a></h1>\n<p>`# -<em>- coding:utf-8 -</em>-`</p>\n<p><code>'''</code></p>\n<p><code>\\* @Author: THSWind</code></p>\n<p><code>\\* @Date: 2019-11-05 17:53:34</code></p>\n<p><code>'''</code></p>\n<p><code>import numpy as np</code></p>\n<p><code>from keras.datasets import mnist</code></p>\n<p><code>from keras.utils import np_utils</code></p>\n<p><code>from keras.models import Sequential</code></p>\n<p><code>from keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten</code></p>\n<p><code>from keras.optimizers import Adam</code></p>\n<p><code>\\# 载入数据</code></p>\n<p><code>(x_train,y_train),(x_test,y_test)= mnist.load_data()</code></p>\n<p><code>\\# (60000,28,28)</code></p>\n<p><code>\\#(60000,28,28)-&gt;(60000,28,28,1)   1是图片的深度，灰度模式</code></p>\n<p><code>x_train=x_train.reshape(-1,28,28,1)/255.0</code></p>\n<p><code>x_test=x_test.reshape(-1,28,28,1)/255.0</code></p>\n<p><code>\\# 转化label为 one-hot格式</code></p>\n<p><code>y_train=np_utils.to_categorical(y_train, num_classes=10)</code></p>\n<p><code>y_test=np_utils.to_categorical(y_test, num_classes=10)</code></p>\n<p><code>\\# 定义顺序模型</code></p>\n<p><code>model = Sequential()</code></p>\n<p><code>\\#第一个卷积层</code></p>\n<p><code>\\# input_shape 输入平面</code></p>\n<p><code>\\# filters 卷积核/滤波器个数</code></p>\n<p><code>\\# kernel_size 卷积窗口大小</code></p>\n<p><code>\\# strides 步长</code></p>\n<p><code>\\# padding padding方式  same/valid</code></p>\n<p><code>\\# activation 激活函数</code></p>\n<p><code>model.add(Convolution2D(</code></p>\n<p>​    <code>input_shape = (28,28,1),</code></p>\n<p>​    <code>filters=32,</code></p>\n<p>​    <code>kernel_size=5,</code></p>\n<p>​    <code>strides=1,</code></p>\n<p>​    <code>padding='same',</code></p>\n<p>​    <code>activation='relu'</code></p>\n<p><code>))</code></p>\n<p><code>\\#第一个池化层</code></p>\n<p><code>model.add(MaxPooling2D(</code></p>\n<p>​    <code>pool_size=2,</code></p>\n<p>​    <code>strides=2,</code></p>\n<p>​    <code>padding='same',</code></p>\n<p><code>))</code></p>\n<p><code>\\#第二个卷积层</code></p>\n<p><code>model.add(Convolution2D(</code></p>\n<p>​    <code>64,</code></p>\n<p>​    <code>5,</code></p>\n<p>​    <code>strides=1,</code></p>\n<p>​    <code>padding='same',</code></p>\n<p>​    <code>activation='relu'</code></p>\n<p><code>))</code></p>\n<p><code>\\#第二个池化层</code></p>\n<p><code>model.add(MaxPooling2D(2,2,'same',))</code></p>\n<p><code>\\#把第二个池化层的输出扁平化为1维</code></p>\n<p><code>model.add(Flatten())</code></p>\n<p><code>\\#第一个全连接层</code></p>\n<p><code>model.add(Dense(1024,activation='relu'))</code></p>\n<p><code>\\# dropout</code></p>\n<p><code>model.add(Dropout(0.5))</code></p>\n<p><code>\\#第二个全连接层</code></p>\n<p><code>model.add(Dense(10,activation='softmax'))</code></p>\n<p><code>\\#定义优化器</code></p>\n<p><code>adam=Adam(lr=1e-4)</code></p>\n<p><code>\\#定义优化器，loss function， 训练过程中计算准确率</code></p>\n<p><code>model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])</code></p>\n<p><code>\\#训练模型</code></p>\n<p><code>model.fit(x_train,y_train,batch_size=64,epochs=10)</code></p>\n<p><code>\\#评估模型</code></p>\n<p><code>loss,accuracy=model.evaluate(x_test,y_test)</code></p>\n<p><code>print('test loss',loss)</code></p>\n<p><code>print('test accuracy', accuracy)</code></p>\n<h1 id=\"9-rnn应用\">9 RNN应用<a title=\"#9-rnn应用\" href=\"#9-rnn应用\"></a></h1>\n<p>RNN用于手写数字识别（结果表明，还是卷积神经网络适合一点，RNN不适用于手写数字识别，准确率没卷积神经网络高。）</p>\n<p>`# -<em>- coding:utf-8 -</em>-`</p>\n<p><code>'''</code></p>\n<p><code>\\* @Author: THSWind</code></p>\n<p><code>\\* @Date: 2019-11-05 18:40:33</code></p>\n<p><code>'''</code></p>\n<p><code>import numpy as np</code></p>\n<p><code>from keras.datasets import mnist</code></p>\n<p><code>from keras.utils import np_utils</code></p>\n<p><code>from keras.models import Sequential</code></p>\n<p><code>from keras.layers import Dense</code></p>\n<p><code>from keras.layers.recurrent import SimpleRNN</code></p>\n<p><code>from keras.optimizers import Adam</code></p>\n<p><code>\\# 数据长度 一行有28个像素</code></p>\n<p><code>input_size = 28</code></p>\n<p><code>\\# 序列长度 一共有28行</code></p>\n<p><code>time_steps = 28</code></p>\n<p><code>\\# 隐藏层 cell 个数</code></p>\n<p><code>cell_size = 50</code></p>\n<p><code>\\# 载入数据</code></p>\n<p><code>(x_train, y_train), (x_test, y_test) = mnist.load_data()</code></p>\n<p><code>\\#(60000,28,28)</code></p>\n<p><code>x_train=x_train/255.0</code></p>\n<p><code>x_test=x_test/255.0</code></p>\n<p><code>\\# 换 one hot格式</code></p>\n<p><code>y_train = np_utils.to_categorical(y_train, num_classes=10)</code></p>\n<p><code>y_test = np_utils.to_categorical(y_test, num_classes=10)</code></p>\n<p><code>\\# 创建模型</code></p>\n<p><code>model= Sequential()</code></p>\n<p><code>\\# 循环神经网络</code></p>\n<p><code>model.add(SimpleRNN(</code></p>\n<p>​    <code>units=cell_size, # 输出</code></p>\n<p>​    <code>input_shape = (time_steps, input_size), # 输入</code></p>\n<p><code>))</code></p>\n<p><code>\\# 输出层</code></p>\n<p><code>model.add(Dense(10, activation='softmax'))</code></p>\n<p><code>\\# 定义优化器</code></p>\n<p><code>adam = Adam(lr=1e-4)</code></p>\n<p><code>\\# 定义优化器，loss function， 训练过程中计算准确率</code></p>\n<p><code>model.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])</code></p>\n<p><code>\\# 训练模型</code></p>\n<p><code>model.fit(x_train,y_train,batch_size=64,epochs=10)</code></p>\n<p><code>\\#评估模型</code></p>\n<p><code>loss, accuracy= model.evaluate(x_test, y_test)</code></p>\n<p><code>print('test loss', loss)</code></p>\n<p><code>print('test accuracy', accuracy)</code></p>\n<h1 id=\"10-keras-模型的保存与载入\">10 keras 模型的保存与载入<a title=\"#10-keras-模型的保存与载入\" href=\"#10-keras-模型的保存与载入\"></a></h1>\n<h2 id=\"保存\">保存<a title=\"#保存\" href=\"#保存\"></a></h2>\n<ul>\n<li>\n<p>保存模型以及参数</p>\n<p><code>model.save('model.h5')   # HDF5文件， pip install h5py</code></p>\n</li>\n<li>\n<p>只保存参数，与载入参数</p>\n<p><code>model.save_weights('my_model_weights.h5')</code></p>\n<p><code>model.load_weights('my_model_weights.h5')</code></p>\n</li>\n<li>\n<p>保存网络结构，与载入网络结构</p>\n<p><code>from keras.models import model_from_json</code></p>\n<p><code>......</code></p>\n<p><code>json_string = model.to_json()</code></p>\n<p><code>model = model_from_json(json_string)</code></p>\n</li>\n</ul>\n<h2 id=\"载入\">载入<a title=\"#载入\" href=\"#载入\"></a></h2>\n<p><code>from keras.models import load_model</code></p>\n<p><code>......</code></p>\n<p><code>#载入模型</code></p>\n<p><code>model = load_model('model.h5')</code></p>\n<p><code>#评估模型</code></p>\n<p><code>loss, accurach = model.evaluate(x_test, y_test)</code></p>\n<p><code>print('\\ntest loss', loss)</code></p>\n<p><code>print('accuracy', accuracy)</code></p>\n","prev":{"title":"Browser-related problems and solutions","link":"2019/11/05/Browser related issues"},"next":{"title":"tensorflow2.0 notes","link":"2019/11/05/tensorflow2.0 notes"},"plink":"http://thswind.github.io/2019/11/05/Tensorflow-keras notes/","toc":[{"id":"1-keras介绍与安装","title":"1 keras介绍与安装","index":"1"},{"id":"2-keras实现线性回归","title":"2 keras实现线性回归","index":"2"},{"id":"3-keras非线性回归","title":"3 keras非线性回归","index":"3"},{"id":"4-mnist分类程序","title":"4 MNIST分类程序","index":"4"},{"id":"5-交叉熵应用","title":"5 交叉熵应用","index":"5"},{"id":"6-dropout","title":"6 Dropout","index":"6"},{"id":"7-正则化","title":"7 正则化","index":"7"},{"id":"8-cnn手写识别","title":"8 CNN手写识别","index":"8"},{"id":"9-rnn应用","title":"9 RNN应用","index":"9"},{"id":"10-keras-模型的保存与载入","title":"10 keras 模型的保存与载入","index":"10","children":[{"id":"保存","title":"保存","index":"10.1"},{"id":"载入","title":"载入","index":"10.2"}]}],"reading_time":"1722 words in 11 min"}